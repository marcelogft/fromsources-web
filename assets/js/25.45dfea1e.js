(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{335:function(e,a,t){"use strict";t.r(a);var s=t(24),r=Object(s.a)({},function(){var e=this,a=e.$createElement,t=e._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[t("img",{attrs:{src:"https://kafka.apache.org/22/images/kafka-apis.png",alt:"An image"}})]),e._v(" "),t("h1",{attrs:{id:"publish-subscribe"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#publish-subscribe","aria-hidden":"true"}},[e._v("#")]),e._v(" Publish/subscribe")]),e._v(" "),t("p",[e._v("Publish/subscribe messaging is a pattern that is characterized by the sender (publisher) of a piece of data (message) not specifically directing it to a receiver. Instead, the publisher classifies the message somehow, and that receiver (subscriber) subscribes to receive certain classes of messages. Pub/sub systems often have a broker, a central point where messages are published, to facilitate this.")]),e._v(" "),t("h1",{attrs:{id:"apache-kafka"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#apache-kafka","aria-hidden":"true"}},[e._v("#")]),e._v(" Apache Kafka")]),e._v(" "),t("p",[e._v("Apache Kafka is a publish/subscribe messaging system. It is often described as a “distributed commit log” or more recently as a “distributing streaming platform.”\nData within Kafka is stored durably, in order, and can be read deterministically. In addition, the data can be distributed within the system to provide additional protections against failures, as well as significant opportunities for scaling performance.")]),e._v(" "),t("p",[e._v("Goals:")]),e._v(" "),t("ul",[t("li",[e._v("Decouple producers and consumers by using a push-pull model")]),e._v(" "),t("li",[e._v("Provide persistence for message data within the messaging system to allow multiple consumers")]),e._v(" "),t("li",[e._v("Optimize for high throughput of messages")]),e._v(" "),t("li",[e._v("Allow for horizontal scaling of the system to grow as the data streams grew.")])]),e._v(" "),t("p",[e._v("The unit of data within Kafka is called a "),t("strong",[e._v("message")]),e._v(" => array of bytes\n"),t("strong",[e._v("KEY")]),e._v(" (optional) => Message metadata => byte array")]),e._v(" "),t("p",[t("strong",[e._v("Batches")]),e._v(": Messages are written into Kafka in batches. Reduces overhead of individual roundtrips acroos the network, for each meessage.\nBatches are typically compressed => more efficient data transfer.")]),e._v(" "),t("h2",{attrs:{id:"schemas"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#schemas","aria-hidden":"true"}},[e._v("#")]),e._v(" Schemas")]),e._v(" "),t("p",[e._v("A consistent data format is important in Kafka, as it allows writing and reading messages\nto be decoupled")]),e._v(" "),t("p",[e._v("By using well-defined schemas and storing them in a common repository, the messages in Kafka can be understood without coordination.")]),e._v(" "),t("p",[e._v("JSON / XML  => Lack features such as robust type handling and compability between schema versions."),t("br"),e._v(" "),t("strong",[e._v("Apache Avro")]),e._v(", serialization framework.")]),e._v(" "),t("ul",[t("li",[e._v("Compact serialization format, schemas that are separate from the message payloads")]),e._v(" "),t("li",[e._v("Do not rqueire code to be generated when they change")]),e._v(" "),t("li",[e._v("String data typing and schema evolution.")]),e._v(" "),t("li",[e._v("Backward and forward compatibility.")])]),e._v(" "),t("h2",{attrs:{id:"topics"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#topics","aria-hidden":"true"}},[e._v("#")]),e._v(" Topics")]),e._v(" "),t("p",[e._v("Messages in Kafka are categorized into "),t("strong",[e._v("topics")]),e._v("\nTopics are additionally broken down into a\nnumber of partitions\nA topic typically has multiple partitions, there is\nno guarantee of message time-ordering across the entire topic, just within a single partition.")]),e._v(" "),t("p",[t("strong",[e._v("Partitions")]),e._v(" are also the way that Kafka provides redundancy and scalability. Each partition can be hosted on a different server, which means that a\nsingle topic can be scaled horizontally across multiple servers to provide performance\nfar beyond the ability of a single server.")]),e._v(" "),t("h2",{attrs:{id:"producers-and-consumers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#producers-and-consumers","aria-hidden":"true"}},[e._v("#")]),e._v(" Producers and Consumers")]),e._v(" "),t("p",[t("strong",[e._v("Producers")]),e._v(" create new messages (publishers/writers).\nA message will be produced to a specific topic.\nThe producer does not care what partition a specific message is written to and will balance messages over all partitions of a topic evenly.\nIn some cases, the producer will direct messages to specific partitions. This is typically done using the message key and a partitioner that will generate a hash of the key and map it to a specific\npartition. This assures that all messages produced with a given key will get written to\nthe same partition")]),e._v(" "),t("p",[t("strong",[e._v("Consumers")]),e._v(" read messages. (subscribers/readers).\nThe consumer subscribes to one or more topics and\nreads the messages in the order in which they were produced. The consumer keeps track of which messages it has already consumed by keeping track of the "),t("em",[e._v("offset")]),e._v(" of messages.")]),e._v(" "),t("p",[t("strong",[e._v("offset")]),e._v(" => integer")]),e._v(" "),t("ul",[t("li",[e._v("Each message in a given partition has a unique offset.")])]),e._v(" "),t("p",[t("strong",[e._v("Consumer group")]),e._v(" => consumers that work together to consume a topic.\nEach partition is only consumed by one member.\nThe mapping of a consumer to a partition is often called "),t("strong",[e._v("ownership of the partition")]),e._v(" by the consumer.")]),e._v(" "),t("h1",{attrs:{id:"brokers-and-clusters"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#brokers-and-clusters","aria-hidden":"true"}},[e._v("#")]),e._v(" Brokers and Clusters")]),e._v(" "),t("p",[e._v("Broker => Kafka server. Operate as part of a "),t("em",[e._v("cluster")]),e._v(".")]),e._v(" "),t("p",[e._v("Broker receives messages from producers => assigns offsets to them => commits the messages to storage on disk.")]),e._v(" "),t("p",[e._v("Broker serve consumers => respond to fetch requests for partitions and responding with the messages.")]),e._v(" "),t("p",[e._v("Controller => one broker will also function as the cluster "),t("em",[e._v("controller")]),e._v("\nAdmin operaitons:")]),e._v(" "),t("ul",[t("li",[e._v("Assigning partitions to brokers")]),e._v(" "),t("li",[e._v("Monitoring for broker failures")])]),e._v(" "),t("p",[e._v("The "),t("em",[e._v("leader of the partition")]),e._v(" => partition is owned by a single broker in the cluster. A partition may be assigned to multiple brokers, which will result in the partition being replicated. Another broker can take over leadership if there is a broker failure. However, all consumers and producers operating on that partition must connect to the leader.")]),e._v(" "),t("h2",{attrs:{id:"retention"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#retention","aria-hidden":"true"}},[e._v("#")]),e._v(" Retention")]),e._v(" "),t("p",[e._v("The durable storage of messages for some period of time. Kafka brokers are configured with a default retention setting for topics, either retaining messages for some period of time or until the topic reaches a certain size in bytes. Once these limits are reached, messages are expired and deleted so that the retention configuration is a minimum amount of data available at any time.\nIndividual topics can also be configured with their own retention settings. Topics can also be configured as "),t("em",[e._v("log compacted")]),e._v(" => Kafka will retain only the last message produced with a specific key. This can be useful for changelog-type data, where\nonly the last update is interesting.")]),e._v(" "),t("h2",{attrs:{id:"multiple-clusters"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#multiple-clusters","aria-hidden":"true"}},[e._v("#")]),e._v(" Multiple Clusters")]),e._v(" "),t("ul",[t("li",[e._v("Segregation of types of data")]),e._v(" "),t("li",[e._v("Isolation for security requirements")]),e._v(" "),t("li",[e._v("Multiple datacenters (disaster recovery)")])]),e._v(" "),t("p",[e._v("The replication mechanisms within the Kafka lusters are designed only to work within a single cluster, not between multiple clusters.")]),e._v(" "),t("p",[t("strong",[e._v("MirrorMaker")]),e._v(" => Kafka consumer and producer, linked together with a\nqueue. Messages are consumed from one Kafka cluster and produced for another.")]),e._v(" "),t("h2",{attrs:{id:"multiple-producers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#multiple-producers","aria-hidden":"true"}},[e._v("#")]),e._v(" Multiple Producers")]),e._v(" "),t("h2",{attrs:{id:"multiple-consumers"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#multiple-consumers","aria-hidden":"true"}},[e._v("#")]),e._v(" Multiple Consumers")]),e._v(" "),t("h2",{attrs:{id:"disk-based-retention"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#disk-based-retention","aria-hidden":"true"}},[e._v("#")]),e._v(" Disk-Based Retention")]),e._v(" "),t("p",[e._v("Consumers do not always need to work in real time. Durable retention\nmeans that if a consumer falls behind, either due to slow processing or a burst in traffic, there is no danger of losing data.")]),e._v(" "),t("h2",{attrs:{id:"scalable"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#scalable","aria-hidden":"true"}},[e._v("#")]),e._v(" Scalable")]),e._v(" "),t("p",[e._v("Start with a single broker => expand to a larger cluster.\nExpansions can be performed while the cluster is online, with no impact.")]),e._v(" "),t("p",[t("strong",[e._v("High Performance")]),e._v("\nApache Kafka carries messages between the various members of the infrastructure, providing a consistent interface for all clients")]),e._v(" "),t("h1",{attrs:{id:"use-cases"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#use-cases","aria-hidden":"true"}},[e._v("#")]),e._v(" Use Cases")]),e._v(" "),t("ul",[t("li",[e._v("Activity tracking")]),e._v(" "),t("li",[e._v("Messaging")]),e._v(" "),t("li",[e._v("Metrics and logging")]),e._v(" "),t("li",[e._v("Commit log")]),e._v(" "),t("li",[e._v("Stream processing")])])])},[],!1,null,null,null);a.default=r.exports}}]);